{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jack/miniconda3/envs/VLLM_env/bin/python\n",
      "3.10.16 (main, Dec 11 2024, 16:24:50) [GCC 11.2.0]\n",
      "1.26.4\n",
      "2.2.1+cu121 True\n",
      "Transformers版本兼容！\n"
     ]
    }
   ],
   "source": [
    "#导入依赖\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "from PIL import Image\n",
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "from awq import AutoAWQForCausalLM\n",
    "import torch\n",
    "import numpy\n",
    "print(numpy.__version__)\n",
    "print(torch.__version__, torch.cuda.is_available())  # 显示 PyTorch 版本和 CUDA 可用性\n",
    "from transformers import Qwen2_5_VLForConditionalGeneration\n",
    "print('Transformers版本兼容！')  # 确认 Transformers 版本兼容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf442247c7434d6295f850b79238b6e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "# 加载模型与处理器（自动分配显存）\n",
    "model_path = \"/home/jack/桌面/Qwen2.5-VL-7B-Instruct-AWQ\"\n",
    "\n",
    "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    model_path,\n",
    "    device_map={\"\": \"cuda:0\"},\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.float16,  # AWQ模型推荐使用半精度\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在处理图像：plot1(1).png\n",
      "正在处理图像：plot1(2).png\n",
      "正在处理图像：plot1(3).png\n",
      "正在处理图像：plot1(4).png\n",
      "正在处理图像：plot1(5).png\n",
      "正在处理图像：plot1(6).png\n",
      "正在处理图像：plot1(7).png\n",
      "正在处理图像：plot1(8).png\n",
      "正在处理图像：plot1(9).png\n",
      "正在处理图像：plot2(1).png\n",
      "正在处理图像：plot2(2).png\n",
      "正在处理图像：plot2(3).png\n",
      "正在处理图像：plot2(4).png\n",
      "正在处理图像：plot2(5).png\n",
      "正在处理图像：plot2(6).png\n",
      "正在处理图像：plot2(7).png\n",
      "正在处理图像：plot2(8).png\n",
      "正在处理图像：plot2(9).png\n",
      "正在处理图像：plot3(1).png\n",
      "正在处理图像：plot3(2).png\n",
      "正在处理图像：plot3(3).png\n",
      "正在处理图像：plot3(4).png\n",
      "正在处理图像：plot3(5).png\n",
      "正在处理图像：plot3(6).png\n",
      "正在处理图像：plot3(7).png\n",
      "正在处理图像：plot3(8).png\n",
      "正在处理图像：plot3(9).png\n",
      "正在处理图像：plot4(1).png\n",
      "正在处理图像：plot4(2).png\n",
      "正在处理图像：plot4(3).png\n",
      "正在处理图像：plot4(4).png\n",
      "正在处理图像：plot4(5).png\n",
      "正在处理图像：plot4(6).png\n",
      "正在处理图像：plot4(7).png\n",
      "正在处理图像：plot4(8).png\n",
      "正在处理图像：plot5(1).png\n",
      "正在处理图像：plot5(2).png\n",
      "正在处理图像：plot5(3).png\n",
      "正在处理图像：plot5(4).png\n",
      "正在处理图像：plot5(5).png\n",
      "正在处理图像：plot5(6).png\n",
      "正在处理图像：plot5(7).png\n",
      "正在处理图像：plot5(8).png\n",
      "正在处理图像：plot6(1).png\n",
      "正在处理图像：plot6(2).png\n",
      "正在处理图像：plot6(3).png\n",
      "正在处理图像：plot6(4).png\n",
      "正在处理图像：plot6(5).png\n",
      "正在处理图像：plot6(6).png\n",
      "正在处理图像：plot6(7).png\n",
      "正在处理图像：plot6(8).png\n",
      "正在处理图像：plot6(9).png\n",
      "正在处理图像：plot7(1).png\n",
      "正在处理图像：plot7(2).png\n",
      "正在处理图像：plot7(3).png\n",
      "正在处理图像：plot7(4).png\n",
      "正在处理图像：plot7(5).png\n",
      "正在处理图像：plot7(6).png\n",
      "正在处理图像：plot7(7).png\n",
      "正在处理图像：plot7(8).png\n",
      "正在处理图像：plot8(1).png\n",
      "正在处理图像：plot8(2).png\n",
      "正在处理图像：plot8(3).png\n",
      "正在处理图像：plot8(4).png\n",
      "正在处理图像：plot8(5).png\n",
      "正在处理图像：plot8(6).png\n",
      "正在处理图像：plot8(7).png\n",
      "正在处理图像：plot8(8).png\n",
      "正在处理图像：plot8(9).png\n",
      "正在处理图像：plot8(10).png\n",
      "正在处理图像：plot9(1).png\n",
      "正在处理图像：plot9(2).png\n",
      "正在处理图像：plot9(3).png\n",
      "正在处理图像：plot9(4).png\n",
      "正在处理图像：plot9(5).png\n",
      "正在处理图像：plot9(6).png\n",
      "正在处理图像：plot9(7).png\n",
      "正在处理图像：plot9(8).png\n",
      "正在处理图像：plot10(1).png\n",
      "正在处理图像：plot10(2).png\n",
      "正在处理图像：plot10(3).png\n",
      "正在处理图像：plot10(4).png\n",
      "正在处理图像：plot10(5).png\n",
      "正在处理图像：plot10(6).png\n",
      "正在处理图像：plot10(7).png\n",
      "正在处理图像：plot10(8).png\n",
      "正在处理图像：plot10(9).png\n",
      "正在处理图像：plot11(1).png\n",
      "正在处理图像：plot11(2).png\n",
      "正在处理图像：plot11(3).png\n",
      "正在处理图像：plot11(4).png\n",
      "正在处理图像：plot11(5).png\n",
      "正在处理图像：plot11(6).png\n",
      "正在处理图像：plot11(7).png\n",
      "正在处理图像：plot11(8).png\n",
      "正在处理图像：plot12(1).png\n",
      "正在处理图像：plot12(2).png\n",
      "正在处理图像：plot12(3).png\n",
      "正在处理图像：plot12(4).png\n",
      "正在处理图像：plot13(1).png\n",
      "正在处理图像：plot13(2).png\n",
      "正在处理图像：plot13(3).png\n",
      "正在处理图像：plot13(4).png\n",
      "正在处理图像：plot13(5).png\n",
      "正在处理图像：plot13(6).png\n",
      "正在处理图像：plot13(7).png\n",
      "正在处理图像：plot13(8).png\n",
      "正在处理图像：plot13(9).png\n",
      "正在处理图像：plot14(1).png\n",
      "正在处理图像：plot14(2).png\n",
      "正在处理图像：plot14(3).png\n",
      "正在处理图像：plot14(4).png\n",
      "正在处理图像：plot14(5).png\n",
      "正在处理图像：plot14(6).png\n",
      "正在处理图像：plot14(7).png\n",
      "正在处理图像：plot14(8).png\n",
      "正在处理图像：plot15(1).png\n",
      "正在处理图像：plot15(2).png\n",
      "正在处理图像：plot15(3).png\n",
      "正在处理图像：plot15(4).png\n",
      "正在处理图像：plot15(5).png\n",
      "正在处理图像：plot15(6).png\n",
      "正在处理图像：plot15(7).png\n",
      "正在处理图像：plot15(8).png\n",
      "正在处理图像：plot16(1).png\n",
      "正在处理图像：plot16(2).png\n",
      "正在处理图像：plot16(3).png\n",
      "正在处理图像：plot16(4).png\n",
      "正在处理图像：plot16(5).png\n",
      "正在处理图像：plot16(6).png\n",
      "正在处理图像：plot16(7).png\n",
      "正在处理图像：plot16(8).png\n",
      "正在处理图像：plot16(9).png\n",
      "正在处理图像：plot17(1).png\n",
      "正在处理图像：plot17(2).png\n",
      "正在处理图像：plot17(3).png\n",
      "正在处理图像：plot17(4).png\n",
      "正在处理图像：plot17(5).png\n",
      "正在处理图像：plot17(6).png\n",
      "正在处理图像：plot17(7).png\n",
      "正在处理图像：plot17(8).png\n",
      "正在处理图像：plot17(9).png\n",
      "正在处理图像：plot17(10).png\n",
      "正在处理图像：plot18(1).png\n",
      "正在处理图像：plot18(2).png\n",
      "正在处理图像：plot18(3).png\n",
      "正在处理图像：plot18(4).png\n",
      "正在处理图像：plot18(5).png\n",
      "正在处理图像：plot18(6).png\n",
      "正在处理图像：plot18(7).png\n",
      "正在处理图像：plot19(1).png\n",
      "正在处理图像：plot19(2).png\n",
      "正在处理图像：plot19(3).png\n",
      "正在处理图像：plot19(4).png\n",
      "正在处理图像：plot19(5).png\n",
      "正在处理图像：plot19(6).png\n",
      "正在处理图像：plot20(1).png\n",
      "正在处理图像：plot20(2).png\n",
      "正在处理图像：plot20(3).png\n",
      "正在处理图像：plot20(4).png\n",
      "正在处理图像：plot20(5).png\n",
      "正在处理图像：plot20(6).png\n",
      "正在处理图像：plot20(7).png\n",
      "正在处理图像：plot21(1).png\n",
      "正在处理图像：plot21(2).png\n",
      "正在处理图像：plot21(3).png\n",
      "正在处理图像：plot21(4).png\n",
      "正在处理图像：plot21(5).png\n",
      "正在处理图像：plot21(6).png\n",
      "正在处理图像：plot22(1).png\n",
      "正在处理图像：plot22(2).png\n",
      "正在处理图像：plot22(3).png\n",
      "正在处理图像：plot22(4).png\n",
      "正在处理图像：plot22(5).png\n",
      "正在处理图像：plot22(6).png\n",
      "正在处理图像：plot22(7).png\n",
      "正在处理图像：plot22(8).png\n",
      "正在处理图像：plot22(9).png\n",
      "正在处理图像：plot23(1).png\n",
      "正在处理图像：plot23(2).png\n",
      "正在处理图像：plot23(3).png\n",
      "正在处理图像：plot23(4).png\n",
      "正在处理图像：plot23(5).png\n",
      "正在处理图像：plot23(6).png\n",
      "正在处理图像：plot23(7).png\n",
      "正在处理图像：plot23(8).png\n",
      "正在处理图像：plot24(1).png\n",
      "正在处理图像：plot24(2).png\n",
      "正在处理图像：plot24(3).png\n",
      "正在处理图像：plot24(4).png\n",
      "正在处理图像：plot24(5).png\n",
      "正在处理图像：plot24(6).png\n",
      "正在处理图像：plot25(1).png\n",
      "正在处理图像：plot25(2).png\n",
      "正在处理图像：plot25(3).png\n",
      "正在处理图像：plot25(4).png\n",
      "正在处理图像：plot26(1).png\n",
      "正在处理图像：plot26(2).png\n",
      "正在处理图像：plot26(3).png\n",
      "正在处理图像：plot26(4).png\n",
      "正在处理图像：plot26(5).png\n",
      "正在处理图像：plot26(6).png\n",
      "正在处理图像：plot26(7).png\n",
      "正在处理图像：plot26(8).png\n",
      "正在处理图像：plot27(1).png\n",
      "正在处理图像：plot27(2).png\n",
      "正在处理图像：plot27(3).png\n",
      "正在处理图像：plot27(4).png\n",
      "正在处理图像：plot27(5).png\n",
      "正在处理图像：plot28(1).png\n",
      "正在处理图像：plot28(2).png\n",
      "正在处理图像：plot28(3).png\n",
      "正在处理图像：plot28(4).png\n",
      "正在处理图像：plot28(5).png\n",
      "正在处理图像：plot28(6).png\n",
      "正在处理图像：plot29(1).png\n",
      "正在处理图像：plot29(2).png\n",
      "正在处理图像：plot29(3).png\n",
      "正在处理图像：plot29(4).png\n",
      "正在处理图像：plot30(1).png\n",
      "正在处理图像：plot30(2).png\n",
      "正在处理图像：plot30(3).png\n",
      "正在处理图像：plot30(4).png\n",
      "正在处理图像：plot31(1).png\n",
      "正在处理图像：plot31(2).png\n",
      "正在处理图像：plot31(3).png\n",
      "正在处理图像：plot31(4).png\n",
      "正在处理图像：plot32(1).png\n",
      "正在处理图像：plot32(2).png\n",
      "正在处理图像：plot32(3).png\n",
      "正在处理图像：plot32(4).png\n",
      "正在处理图像：plot33(1).png\n",
      "正在处理图像：plot33(2).png\n",
      "正在处理图像：plot33(3).png\n",
      "正在处理图像：plot33(4).png\n",
      "正在处理图像：plot33(5).png\n",
      "正在处理图像：plot33(6).png\n",
      "正在处理图像：plot33(7).png\n",
      "正在处理图像：plot34(1).png\n",
      "正在处理图像：plot34(2).png\n",
      "正在处理图像：plot34(3).png\n",
      "正在处理图像：plot34(4).png\n",
      "正在处理图像：plot34(5).png\n",
      "正在处理图像：plot34(6).png\n",
      "正在处理图像：plot35(1).png\n",
      "正在处理图像：plot35(2).png\n",
      "正在处理图像：plot35(3).png\n",
      "正在处理图像：plot35(4).png\n",
      "正在处理图像：plot36(1).png\n",
      "正在处理图像：plot36(2).png\n",
      "正在处理图像：plot36(3).png\n",
      "正在处理图像：plot36(4).png\n",
      "正在处理图像：plot37(1).png\n",
      "正在处理图像：plot37(2).png\n",
      "正在处理图像：plot37(3).png\n",
      "正在处理图像：plot37(4).png\n",
      "正在处理图像：plot37(5).png\n",
      "正在处理图像：plot37(6).png\n",
      "正在处理图像：plot38(1).png\n",
      "正在处理图像：plot38(2).png\n",
      "正在处理图像：plot38(3).png\n",
      "正在处理图像：plot38(4).png\n",
      "正在处理图像：plot38(5).png\n",
      "正在处理图像：plot38(6).png\n",
      "正在处理图像：plot39(1).png\n",
      "正在处理图像：plot39(2).png\n",
      "正在处理图像：plot39(3).png\n",
      "正在处理图像：plot39(4).png\n",
      "正在处理图像：plot39(5).png\n",
      "正在处理图像：plot39(6).png\n",
      "正在处理图像：plot40(1).png\n",
      "正在处理图像：plot40(2).png\n",
      "正在处理图像：plot40(3).png\n",
      "正在处理图像：plot40(4).png\n",
      "正在处理图像：plot40(5).png\n",
      "正在处理图像：plot40(6).png\n",
      "正在处理图像：plot41(1).png\n",
      "正在处理图像：plot41(2).png\n",
      "正在处理图像：plot41(3).png\n",
      "正在处理图像：plot41(4).png\n",
      "正在处理图像：plot41(5).png\n",
      "正在处理图像：plot41(6).png\n",
      "正在处理图像：plot42(1).png\n",
      "正在处理图像：plot42(2).png\n",
      "正在处理图像：plot42(3).png\n",
      "正在处理图像：plot42(4).png\n",
      "正在处理图像：plot42(5).png\n",
      "正在处理图像：plot43(1).png\n",
      "正在处理图像：plot43(2).png\n",
      "正在处理图像：plot43(3).png\n",
      "正在处理图像：plot43(4).png\n",
      "正在处理图像：plot43(5).png\n",
      "正在处理图像：plot44(1).png\n",
      "正在处理图像：plot44(2).png\n",
      "正在处理图像：plot44(3).png\n",
      "正在处理图像：plot44(4).png\n",
      "正在处理图像：plot45(1).png\n",
      "正在处理图像：plot45(2).png\n",
      "正在处理图像：plot45(3).png\n",
      "正在处理图像：plot45(4).png\n",
      "正在处理图像：plot45(5).png\n",
      "正在处理图像：plot46(1).png\n",
      "正在处理图像：plot46(2).png\n",
      "正在处理图像：plot46(3).png\n",
      "正在处理图像：plot46(4).png\n",
      "正在处理图像：plot46(5).png\n",
      "正在处理图像：plot47(1).png\n",
      "正在处理图像：plot47(2).png\n",
      "正在处理图像：plot47(3).png\n",
      "正在处理图像：plot47(4).png\n",
      "正在处理图像：plot47(5).png\n",
      "正在处理图像：plot48(1).png\n",
      "正在处理图像：plot48(2).png\n",
      "正在处理图像：plot48(3).png\n",
      "正在处理图像：plot48(4).png\n",
      "正在处理图像：plot48(5).png\n",
      "正在处理图像：plot49(1).png\n",
      "正在处理图像：plot49(2).png\n",
      "正在处理图像：plot49(3).png\n",
      "正在处理图像：plot49(4).png\n",
      "正在处理图像：plot49(5).png\n",
      "正在处理图像：plot49(6).png\n",
      "正在处理图像：plot50(1).png\n",
      "正在处理图像：plot50(2).png\n",
      "正在处理图像：plot50(3).png\n",
      "正在处理图像：plot50(4).png\n",
      "批注已保存至：/home/jack/桌面/qwen_vl_dataset/annotations.json\n",
      "所有批注生成完成！\n"
     ]
    }
   ],
   "source": [
    "# 定义生成单张图像批注的函数\n",
    "def generate_annotation(image_path):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\", \"image\": image_path},\n",
    "            {\"type\": \"text\", \"text\": \"\"\"分析自动驾驶BEV视频流，图像元素如下：白色矩形：自身车辆（ego vehicle），位于视野中央。\n",
    "            绿色矩形及其矢量线段：其他车辆及其位移矢量。紫色圆形及其矢量：行人及其位移矢量。橙色曲线：ego车辆已执行的规\n",
    "            划路径。绿色曲线：ego车辆未来规划未执行的路径。深蓝区域：车辆可行区域。\n",
    "            任务：1.识别长尾场景（如行人突然横穿、盲区物体、异常车辆行为、哪些时间区段需要等待礼让），避免强制预警，适当预测行人与车辆的移动意图，如果\n",
    "            现有行人/车辆与自车干涉概率低可适当过滤，距离越近警告优先级越高，仅输出白色车辆高度相关潜在风险的分析;\n",
    "            2.对当前驾驶风格建议：（保守、正常、激进）\n",
    "            3.代入当前帧场景的驾驶者，提醒当前帧时刻大致方位（左/右侧后方）来车（无车辆时可省去），注意图像间的连续运动趋势以及方位描述的准确性\n",
    "            4.无视对向车道的行人和车辆，关注自身车道相关智能体影响干涉\n",
    "            要求：言简意赅：100字左右按重要性顺序高效率汇报,有车辆或行人强调相对自车几点钟方向\"\"\"}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # 预处理\n",
    "    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=False)\n",
    "    image_inputs, _ = process_vision_info(messages)\n",
    "    inputs = processor(\n",
    "        text=[text],\n",
    "        images=image_inputs,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    # 推理\n",
    "    generated_ids = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=120,\n",
    "        temperature=0.1,\n",
    "        do_sample=False\n",
    "    )\n",
    "\n",
    "def clean_response(text):\n",
    "    # 处理多级标记\n",
    "    markers = [\"assistant\\n\", \"Assistant:\", \"回答：\"]\n",
    "    for marker in markers:\n",
    "        if marker in text:\n",
    "            return text.split(marker)[-1].strip()\n",
    "    # 兜底处理：移除用户问题关键词\n",
    "    return text.replace(\"分析自动驾驶BEV视频流\", \"\").strip()\n",
    "\n",
    "return clean_response(raw_output)\n",
    "\n",
    "# 批量推理主函数\n",
    "def batch_inference(image_folder, plot_groups=None):\n",
    "    annotations = []\n",
    "    # 获取所有图像文件\n",
    "    image_files = [f for f in os.listdir(image_folder) if f.endswith(('.png', '.jpg'))]\n",
    "    \n",
    "    # 如果未指定 plot_groups，则处理所有图像\n",
    "    if plot_groups is None:\n",
    "        plot_groups = list(set(f.split('(')[0] for f in image_files))\n",
    "\n",
    "    # 按自然顺序排序 (plot1, plot2...plot10)\n",
    "    plot_groups = sorted(\n",
    "        plot_groups,\n",
    "        key=lambda x: int(x.replace('plot', '')),  # 提取数字部分作为排序依据\n",
    "    )\n",
    "    \n",
    "    # 按 plotX 和时序 M 排序\n",
    "    for plot_id in plot_groups:\n",
    "        # 筛选属于当前 plotX 的图像\n",
    "        group_files = [f for f in image_files if f.startswith(plot_id + '(')]\n",
    "        # 按时序 (M) 排序,plotX内部按帧序号排列\n",
    "        group_files = sorted(group_files, key=lambda x: int(x.split('(')[1].split(')')[0]))\n",
    "        \n",
    "        for filename in group_files:\n",
    "            scene_id = filename.split('.')[0]  # 提取完整场景ID，如 plot1(7)\n",
    "            image_path = os.path.join(image_folder, filename)\n",
    "            \n",
    "            # 生成批注\n",
    "            print(f\"正在处理图像：{filename}\")\n",
    "            response = generate_annotation(image_path)\n",
    "            \n",
    "            # 构建 JSON 条目\n",
    "            annotation = {\n",
    "                \"id\": scene_id,\n",
    "                \"image\": filename,\n",
    "                \"conversations\": [\n",
    "                    {\n",
    "                        \"from\": \"human\",\n",
    "                        \"value\": \"<image>\\n对当前场景作合理预警和驾驶提示\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"from\": \"qwen 2.5 vl\",\n",
    "                        \"value\": response\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "            annotations.append(annotation)\n",
    "            # 打印当前批注\n",
    "           # print(f\"场景ID: {scene_id}\")\n",
    "          #  print(f\"图像: {filename}\")\n",
    "          #  print(f\"批注: {response}\")\n",
    "         #   print(\"-\" * 50)\n",
    "    \n",
    "    # 保存批注到 JSON 文件\n",
    "    output_path = os.path.join(image_folder, 'annotations.json')\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(annotations, f, ensure_ascii=False, indent=4)\n",
    "    print(f\"批注已保存至：{output_path}\")\n",
    "    \n",
    "    return annotations\n",
    "\n",
    "# 执行批量推理\n",
    "image_folder = \"/home/jack/桌面/qwen_vl_dataset\"  # 替换为您的图像文件夹路径\n",
    "# 可选：指定特定 plot 组，例如 [\"plot1\", \"plot2\"]\n",
    "# plot_groups = [\"plot1\", \"plot2\"]  # 如果不指定，则处理所有组\n",
    "#plot_groups = [\"plot3\"]  # 默认None处理所有组\n",
    "plot_groups = None\n",
    "\n",
    "annotations = batch_inference(image_folder, plot_groups)\n",
    "print(\"所有批注生成完成！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##以下是版本打印排查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Configuration:\n",
      "PyTorch Version: 2.2.1+cu121\n",
      "CUDA Version: 12.1\n",
      "Transformers Version: 4.52.0.dev0\n",
      "Triton Version: 3.0.0\n",
      "AutoAWQ Version: 0.2.8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "\n",
    "# 检查 PyTorch 版本\n",
    "pytorch_version = torch.__version__\n",
    "cuda_version = torch.version.cuda if torch.cuda.is_available() else \"CUDA not available\"\n",
    "\n",
    "# 检查 Transformers 版本\n",
    "transformers_version = transformers.__version__\n",
    "\n",
    "# Triton 和 AutoAWQ 版本（如果已安装）\n",
    "try:\n",
    "    import triton\n",
    "    triton_version = triton.__version__\n",
    "except ImportError:\n",
    "    triton_version = \"Triton not installed\"\n",
    "\n",
    "try:\n",
    "    import awq\n",
    "    autoawq_version = awq.__version__\n",
    "except ImportError:\n",
    "    autoawq_version = \"AutoAWQ not installed\"\n",
    "\n",
    "# 打印信息\n",
    "print(\"Environment Configuration:\")\n",
    "print(f\"PyTorch Version: {pytorch_version}\")\n",
    "print(f\"CUDA Version: {cuda_version}\")\n",
    "print(f\"Transformers Version: {transformers_version}\")\n",
    "print(f\"Triton Version: {triton_version}\")\n",
    "print(f\"AutoAWQ Version: {autoawq_version}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.1+cu121\n",
      "True\n",
      "tensor(-4821.5889, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "x = torch.randn(1000, 1000, device='cuda')\n",
    "y = x @ x  # 矩阵乘法\n",
    "print(y.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
